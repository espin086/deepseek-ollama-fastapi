# deepseek-ollama-fastapi
A Docker-based solution for running the Deep Seek LLM via Ollama, exposed by a FastAPI application using Uvicorn. This repo includes straightforward endpoints for both synchronous and streaming text-generation requests, making it easy to integrate the “deepseek-r1” model into your own applications.
